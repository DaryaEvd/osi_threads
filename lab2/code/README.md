# Блок задач на синхронизацию  

### Для 2.1  

#### Пункт a
Вспомнить, что такое очередь и [как она работает](https://codelessons.dev/ru/ochered-queue-v-c-realizaciya-i-chto-eto-voobshhe-takoe/).   
На примере [стека](https://prepinsta.com/c-program/implementation-of-queues-using-linked-list/)  

#### Пункт b
При изначальном варианте пограммы `./queue-threads` возникали следующие ошибки:  
`ERROR: get value is 4372464 but expected - 4372463
Segmentation fault (core dumped)`  
или просто 
`Segmentation fault (core dumped)`  

#### А почему получаем такие ошибки?  
Потому что много мест в коде, где есть атомарные операции.
Например, операция увеличения счётчика - не атомарна! 
В коде таких операций много: `q->add_attempts++`, `q->count++`, `q->add_count++` и т.д. 
То есть, условно, `counter++` превращается в 3 операции:  
```
movl    $0, -4(%rbp)
addl    $1, -4(%rbp)
movl    -4(%rbp), %eax
```  
То есть в процессе исполнения этих 3х команд, процесс/поток может быть вытеснен, и в эту последовательность исполнения может вмешаться другой процесс/поток.
В общем, атомарные операцици либо происходят полностью, либо нет.  
Если бы эти команды выполнялись как единое целое, то у нас бы была гарантия, что система не вытеснит процесс/поток, пока мы будем в одном процессе находиться; либо, что процессор у нас выполнит эти 3 инструкции как единую команду, тогда бы было все ок. Но это не так. Поэтому все плохо (с)  


**Полезно!** : [Как смотреть core files?](https://unix.stackexchange.com/questions/89933/how-to-view-core-files-for-debugging-purposes-in-linux)  
Или так: 
`./queue-threads`   
`coredumpctl gdb -1`  
В открывшемся окне видим:  
`Storage: /var/lib/systemd/coredump/core.queue-threads.1000.4808e08477e8414eb47fdb2179cb815e.45697.1698337778000000000000.lz4 (inaccessible)`  
Копируем `/var/lib/systemd/coredump/core.queue-threads.1000.4808e08477e8414eb47fdb2179cb815e.45697.1698337778000000000000.lz4 `  
Затем для удобства пишем в терминальчик (например так):  
`sudo cp  /var/lib/systemd/coredump/core.queue-threads.1000.4808e08477e8414eb47fdb2179cb815e.45697.1698337778000000000000.lz4  ./core`  
`sudo chmod ugo+rwx core`  
`mv ./core core.lz4`  
`unlz4 core.lz4`  
`gdb ./core queue-threads`  
Потом жмякаем на enter и пишем `where`

Получим что-то в таком духе:  
```
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00005605e73446a1 in queue_get (q=0x5605e81196b0, 
    val=0x7eff212f2ec4) at queue.c:102
102       *val = tmp->val;           // take val of the 1st node
[Current thread is 1 (Thread 0x7eff212f3700 (LWP 45699))]
(gdb) where
#0  0x00005605e73446a1 in queue_get (q=0x5605e81196b0, 
    val=0x7eff212f2ec4) at queue.c:102
#1  0x00005605e7344949 in reader (arg=0x5605e81196b0)
    at queue-threads.c:45
#2  0x00007eff21cf2609 in start_thread (arg=<optimized out>)
    at pthread_create.c:477
#3  0x00007eff21c17133 in clone ()
    at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
```  
Пытались забрать `tmp`. Посмотрим, что это такое.   
Пишем дальше:  
`p tmp`  
Получаем вот что:  
`$1 = (qnode_t *) 0x0`  
То есть мы пытались разыменовать нулевой указатель.  
Можем еще посмотреть соседние потоки. Пишем:  
`info thread`  
Получаем:  
```
  Id   Target Id                                   Frame 
* 1    Thread 0x7eff212f3700 (LWP 45699)           0x00005605e73446a1 in queue_get (q=0x5605e81196b0, val=0x7eff212f2ec4) at queue.c:102
  2    Thread 0x7eff20af2700 (LWP 45700)           0x00007eff21b92190 in checked_request2size (sz=<optimized out>, req=<optimized out>)
    at malloc.c:3059
  3    Thread 0x7eff21af4700 (LWP 45698)           0x00007eff21bd523f in __GI___clock_nanosleep (clock_id=clock_id@entry=0, 
    flags=flags@entry=0, req=req@entry=0x7eff21af3e80, 
--Type <RET> for more, q to quit, c to continue without paging--
    eff21af3e80) at ../sysdeps/unix/sysv/linux/clock_nanosleep.c:78
  4    Thread 0x7eff21af5740 (LWP 45697) (Exiting) warning: Couldn't find general-purpose registers in core file.
<unavailable> in ?? ()
```  
Наш поток упал в `queue_get`, а соседний(thread 2) - был в `checked_request2size` (не оч пон чо ито)  
Можем написать для более подробной инфы:  
`thread 2`  
`where`  
Чтоб выйти из gdb пишем `quit`  

То есть у нас есть `tmp=0`. Вопрос: почему?  
Потому что поток что-то успелось сделаться, а что-то нет. Эти неатомарные вещи в конкурентной среде происходят несинхронизированно. 


### Теория про планирование(shed_yield() в частности), SPINLOCK, FUTEX() 

- [Про планирование в Lunux](https://habr.com/ru/companies/ruvds/articles/578788/)  
- Статья про shed_yield() [number1](https://it.wikireading.ru/1764)  
- [number2](https://it.wikireading.ru/1764)  
- [number3](https://www.halolinux.us/kernel-reference/the-sched-yield-system-call.html)  

#### Про CAS-операции and SPINLOCK
[Почитать тут](https://en.wikipedia.org/wiki/Compare-and-swap#:~:text=In%20computer%20science%2C%20compare%2Dand,to%20a%20new%20given%20value.)  

```
cas(&f, expected, new) {
	if(f != expected) {
		return 0;
	}
	f = new;
	return 1;
}
```  
Передаем адрес переменной f, передаем ожидаемое значение и новое значение.
Идея в том, что функция должна АТОМАРНО поменять значение f на new, если там сейчас находится expected.

##### Примерчик с функцией f  
```
// 1 -> 0  
cas(&f, 1, 0);
```
То есть:  
1. Пусть в f была единичка, а мы хотим записать нолик. Сравниваем f с единичкой(2 арг), сравнение прошло успешно, записываем 0. 
2. // 0 -> 0
Пусть в f был 0, тогда cas не прошел, вернул ошибку.  

Если запишем такое:  
`while(!cas(&f, 1, 0))`, то выйдем из этого цикла только при том условии, если в f удастся положить 0 при том, что там была 1. 
Это есть захват лочки (aka lock). Такая лочка называется spinlock.  


#### Про shed_yield() и немного про funtex()  

From the 2nd article украдено:  
```
Состояние «выполняется»

Как только планировщик поставил процесс на выполнение, началось состояние «выполняется». Процесс может выполняться весь предложенный промежуток (квант) времени, а может уступить место другим процессам, воспользовавшись системным вывозом sched_yield.
```

**Из лекций:**  
Что сделает shed_yield? Это сискол, который уйдет в ядро. 
Что значит заблокировать процесс добровольно? 
Процесс может находиться в 3х состояних: `RUN`, `RUNNABLE`, `SLEEP`.  
В `RUNNABLE`оказываемся, когда закончилось процессорное время, а в `SLEEP` - когда что-то случилось: процессорное время есть, но мы не можем им воспользоваться. Например, ожидаем данные из какого-то сокета, или подрубили `shed_yield`.  
Эта функция должна найти структуру task нашего процесса, найти там поле `state` и написать `state = SLEEP`. А потом в shed_yield прописать: `current_state = SLEEEP`.   
И дальше вызываем функцию schedule, который занимается планированием.   
```
shed_yield() {
	current_state = SLEEP;
	schedule();
}
```  
Функция schedule() включилась, видит, что поток в состоянии `SLEEP`, снимает этот поток с исполнения. Берет следующий процесс, точнее его структуру task, берёт его контекст, выставляет там все необходимое окружение.  И затем продолжает исполнение с того места, где закончился предыдущий процесс.   
__А где закончился предыдущий процесс?__   
А он закончился тоже в функции schedule(). Но нам мало просто вытестнить процесс, т.е. просто прописать 
```
task {
	state = SLEEP;
}
```   
будет недостаточно, тк потом процесс надо еще разбудить.  
То есть если функцией shed_yield() мы просто вытесним процесс, то кто разбудит процесс? Ответ: планировщик, когда придет время планировать этот процесс. А мы хотим, чтобы этот процесс проснулся, когда можно захватить лочку (aka lock) &copy;  

Допустим, в ядре есть какая-то функция, которая поместила current_state в `SLEEP`. В это время наша структура `task` поместилась в некий набор структур, который нахолдится в состоянии `SLEEP`.  
```
function1() { 
	current_state = SLEEP;
}       
```  
Но разбудить этот task мы хотим не по тайм-ауту, который прошёл. То есть не хотим, чтоб планировщик разбудил этот процесс, потому что подумал, что пришло время процесса исполняться. Нет.  
Наш task должен ожидать какого-то `event`-a. Это позволит другой функции понять, что процесс (который в `sleep`) ожидает события и прописать `state=RUNNABLE` и поместить его в множество tasks, которые находятся в состоянии `RUNNABLE`.  
```
function2() { 
	current_state = RUNNABLE;
}       
```  
Тогда, когда планироващиу (scheduler) запустится, он сможет из `runnable-процессов` выбрать наиболее достойный и отправить в `RUN`. 
То есть нам нужны 2 такие функии, которые должны быть сисколами:  
1. Первая умеет переводить его в `SLEEP` и как-то помечать, что он ждёт события.  
2. Вторая должна уметь переводить его в состояние `RUNNABLE`, опеределять, что процесс ждёт события и передвать его в `RUN`.  

В Posix это не 2 функции, а одна, но с разными аргументами - `futex()`.  
Это такой швейцарский нож, который на все случаи жизни, умеет много всего. Что-то умеет хорошо, что-то плохо, чем-то пользоваться depricated, потому что слишком много умеет, слишком много может поломать. &copy;Рутман М.В.  
### Про futex() 
Функция нужна для того, чтоб процесс перенести из состояния `RUN` в состояние `SLEEP`, а затем вернуть его в `RUNNABLE` и потом на исполнение.   


